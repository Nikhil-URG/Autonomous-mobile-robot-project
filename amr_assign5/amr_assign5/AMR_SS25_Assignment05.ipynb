{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8dadca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbassignment": {
     "type": "header"
    },
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61c7e7acf8c5bdb945139d60a161a008",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "|        |        |        |\n",
    "|--------|--------|--------|\n",
    "![H-BRS](logos/h-brs.png) | ![A2S](logos/a2s.png) | ![b-it](logos/b-it.png) |\n",
    "\n",
    "# Autonomous Mobile Robots\n",
    "\n",
    "# AMR Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9220f1d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44f7ff21f9522a124e34b5d501542440",
     "grade": false,
     "grade_id": "preamble",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General information\n",
    "\n",
    "* Please do not add or delete any cells. Answers belong into the already provided cells (below the question).\n",
    "* If a function is given (either as a signature or a full function), you should not change the name, arguments, or return value of the function.\n",
    "* If you encounter empty cells underneath the answer that can not be edited, please ignore them; they are for testing purposes.\n",
    "* Please note that variables declared in the notebook cells have global scope. To make sure your assignment works correctly as a whole, please restart the kernel and run all cells before submitting (e.g. via *Kernel -> Restart & Run All*).\n",
    "* Code cells where you are supposed to give your answer often include the line  ```raise NotImplementedError```. This makes it easier to automatically grade answers. Once you fill out a function, please delete this line.\n",
    "\n",
    "### Submission\n",
    "\n",
    "Please make sure to write all your team members 2s IDs in the cell below before submission. Please submit your notebook via the JupyterHub web interface (in the main view -> Assignments -> Submit). If it is a group assignment, please make only one submission per group (for easier bookkeeping, it is best if this is always the same team member).\n",
    "\n",
    "### Questions about the assignment\n",
    "\n",
    "If you have questions about the assignment, you are encouraged to post them in the LEA forum. Proactive discussions lead to better understanding. Let's keep the forum active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c9eb0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc232b5055261266722e1856218944d0",
     "grade": true,
     "grade_id": "team_members",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## Team members (2s IDs):\n",
    "\n",
    "* kabdul2s\n",
    "* nravi2s\n",
    "* ysirin2s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bf078",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81b5f5f4a727d76331cdc6721bdddf11",
     "grade": false,
     "grade_id": "Landmark_based_localisation_Kalman_A_Header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Landmark-based Localisation using Kalman Filter (100 points)\n",
    "\n",
    "In this assignment, we will use a Kalman filter for localisation in an environment based on the measurement of landmark locations. As you already know, sensor readings are affected by noise, making it difficult to achieve accurate measurement of the physical quantity under consideration. The Kalman filter, which belongs to the family of Bayes filter algorithms, can be used for minimising the error in the estimation. The belief of the state (in this case, it is the **pose of the robot** with respect to the **map frame**) is represented as a Gaussian distribution. The objective is to estimate the mean $\\mu$ and covariance matrix $\\Sigma$ for the physical quantity under consideration at every time instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd2aeb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5d2fabf84c59ec19bab11bcd4ed5d76",
     "grade": false,
     "grade_id": "Landmark_based_localisation_Kalman_A_Description0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this assignment, the Robile is placed in a simulation environment in Gazebo, where several RFID tags are positioned on the ground. Now, suppose that a virtual RFID detector is mounted on the robot, sharing the *same frame* and *field of view* as the LiDAR. In the real world, the robot's real pose almost never matches with its ideal motion model due to different sources of noise, such as from the encoder readings, unstructured environment interaction, as well as other noisy perception data.\n",
    "\n",
    "In this assignment, we will explore how the Kalman filter can be employed to improve the estimation of the robot's pose in this setup. Below is the simulation environment where the RFID tags are highlighted.\n",
    "\n",
    "![robile_localisation_kalman](img/robile_localisation_kalman.png)\n",
    "\n",
    "The positions of the RFID tags as $(x,y)$ coordinates in the `odom` frame with tag names are as follows:  \n",
    "- A: $(1.0, 1.0)$\n",
    "- B: $(6.0, 1.0)$\n",
    "- C: $(3.0, -1.0)$\n",
    "- D: $(1.0, -3.0)$\n",
    "- E: $(4.0, -4.0)$\n",
    "\n",
    "### Motion noise consideration\n",
    "\n",
    "When the robot is moving in the environment, the noise in the data published onto the `/odom` topic is negligible in the simulation. To simulate the real-world noise, for every message on the `/odom` topic, some noise is introduced manually in the associated *robile_rfid_tag_finder.py* script, and the variable `real_base_link_pose` is updated accordingly. Here, the data on the `/odom` topic, and consequently the visualization of the robot model in RVIZ, can be considered as an ideal motion model, which is the motion estimate without noise; the data on `real_base_link_pose` is then the actual pose of the robot's base (`real_base_link` frame) with respect to which the RFID tags are measured, and which are available on the `/rfid_tag_poses` topic. The `real_base_link_pose` topic thus represents the actual pose of the robot, which deviates from `/odom` due to uncertain interaction with the environment.\n",
    "\n",
    "Your goal is to read from the `odom` topic and, along with the measured RFID tag positions, estimate the posterior belief of the robot's pose and the variance associated with it. This estimated pose, which should be published to the `estimated_base_link_pose` topic, should eventually converge to the pose represented on `real_laser_link_pose`.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- The pose of the robot with respect to the odom frame, published on the `/odom` topic represents ideal motion without noise.\n",
    "- Since it is challenging to mathematically represent or model all physical interactions with the environment, in reality, the robot deviates from the ideal motion and its pose estimation is affected by noise in the sensor data and an incomplete model of the interaction with the environment. The actual robot pose is considered to be the `real_base_link` frame.\n",
    "- The measurement model is the pose estimate using the detected RFID tags on the `/rfid_tag_poses` topic, which is represented by a custom message of type ``PoseLabelledArray``. These tags are measured with respect to the `real_base_link` frame.\n",
    "- Note that the `real_base_link` frame is only used to visualise the actual robot pose; thus, only the data on `/odom` and `/rfid_tag_poses` topics should be used to determine robot's posterior pose `estimated_base_link_pose`.\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The initial `real_base_link` frame is considered to be overlapping with the `odom` frame.\n",
    "- To determine the robot's pose by the measurement of RFID tag positions, at least two tags needs to be perceived. The problem could be made simpler by considering the pose estimated using these RFID positions as measurement data rather than the measured RFID positions themselves.\n",
    "- The initial state, i.e., the `estimated_base_link_pose` pose at the start of simulation is considered the same as the pose of the `odom` frame, namely `estimated_base_link_pose` can be considered as initially known with zero or constant uncertainty. Optionally, it can be updated using the `2D Pose Estimate` widget in RVIZ, in which case the mean and variance of the estimate should be reset.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Upload the modified `robile_navigation` package with your submission, and also paste your Kalman filter implementation in the cell below. Before starting your implementation please follow these steps:\n",
    "\n",
    "- Modify the simulation launch file to load the `closed_walls.world` environment from the `robile_gazebo` package\n",
    "- Implement pose estimation using a Kalman filter in the `robile_localisation_kalman.py` script from the `robile_navigation` repository\n",
    "- Use the launch file `landmark_based_localisation.launch.py` under `robile_navigation` and modify it accordingly to launch your implementation\n",
    "- Please feel free to modify any of the scripts according to your needs\n",
    "\n",
    "### Potentially useful references\n",
    "\n",
    "- Section 5.6.8.5 in the \"Introduction to Autonomous Mobile Robots\" book. It doesn't have the same setup, but is still useful\n",
    "- https://www.alanzucconi.com/2022/07/24/kalman-gain/\n",
    "- http://bilgin.esme.org/BitsAndBytes/KalmanFilterforDummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b888c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38dd4c5d46700f8aad2fec453d4ca8af",
     "grade": true,
     "grade_id": "Landmark_based_localisation_Kalman_A",
     "locked": false,
     "points": 90,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from geometry_msgs.msg import PoseStamped, PoseWithCovarianceStamped\n",
    "from robile_interfaces.msg import PositionLabelled, PositionLabelledArray\n",
    "from nav_msgs.msg import Odometry\n",
    "import numpy as np\n",
    "import tf2_ros\n",
    "from tf_transformations import euler_from_quaternion, quaternion_from_euler\n",
    "\n",
    "\n",
    "class LocalisationUsingKalmanFilter(Node):\n",
    "    \"\"\"\n",
    "    Landmark based localisation using Kalman Filter\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('localisation_using_kalman_filter')\n",
    "\n",
    "        # declaring and getting parameters from yaml file\n",
    "        self.declare_parameters(\n",
    "            namespace='',\n",
    "            parameters=[\n",
    "                ('map_frame', 'map'),\n",
    "                ('odom_frame', 'odom'),                \n",
    "                ('laser_link_frame', 'base_laser_front_link'),\n",
    "                ('real_base_link_frame', 'real_base_link'),\n",
    "                ('scan_topic', 'scan'),\n",
    "                ('odom_topic', 'odom'),\n",
    "                ('rfid_tag_poses_topic', 'rfid_tag_poses'),\n",
    "                ('initial_pose_topic', 'initialpose'),\n",
    "                ('real_base_link_pose_topic', 'real_base_link_pose'),\n",
    "                ('estimated_base_link_pose_topic', 'estimated_base_link_pose'),\n",
    "                ('minimum_travel_distance', 0.1),\n",
    "                ('minimum_travel_heading', 0.1),\n",
    "                ('rfid_tags.A', [1.0,1.0]),\n",
    "                ('rfid_tags.B', [6.0,1.0]),\n",
    "                ('rfid_tags.C', [3.0,-1.0]),\n",
    "                ('rfid_tags.D', [1.0,-3.0]),\n",
    "                ('rfid_tags.E', [-4.0,4.0]),                        \n",
    "            ])\n",
    "\n",
    "        self.map_frame = self.get_parameter('map_frame').get_parameter_value().string_value\n",
    "        self.odom_frame = self.get_parameter('odom_frame').get_parameter_value().string_value\n",
    "        self.laser_link_frame = self.get_parameter('laser_link_frame').get_parameter_value().string_value\n",
    "        self.real_base_link_frame = self.get_parameter('real_base_link_frame').get_parameter_value().string_value\n",
    "        self.scan_topic = self.get_parameter('scan_topic').get_parameter_value().string_value\n",
    "        self.odom_topic = self.get_parameter('odom_topic').get_parameter_value().string_value\n",
    "        self.rfid_tag_poses_topic = self.get_parameter('rfid_tag_poses_topic').get_parameter_value().string_value\n",
    "        self.initial_pose_topic = self.get_parameter('initial_pose_topic').get_parameter_value().string_value\n",
    "        self.real_base_link_pose_topic = self.get_parameter('real_base_link_pose_topic').get_parameter_value().string_value\n",
    "        self.estimated_base_link_pose_topic = self.get_parameter('estimated_base_link_pose_topic').get_parameter_value().string_value\n",
    "        self.minimum_travel_distance = self.get_parameter('minimum_travel_distance').get_parameter_value().double_value\n",
    "        self.minimum_travel_heading = self.get_parameter('minimum_travel_heading').get_parameter_value().double_value\n",
    "        self.rfid_tags_A = self.get_parameter('rfid_tags.A').get_parameter_value().double_array_value\n",
    "        self.rfid_tags_B = self.get_parameter('rfid_tags.B').get_parameter_value().double_array_value\n",
    "        self.rfid_tags_C = self.get_parameter('rfid_tags.C').get_parameter_value().double_array_value\n",
    "        self.rfid_tags_D = self.get_parameter('rfid_tags.D').get_parameter_value().double_array_value\n",
    "        self.rfid_tags_E = self.get_parameter('rfid_tags.E').get_parameter_value().double_array_value\n",
    "\n",
    "        # Create dictionary of RFID tag positions\n",
    "        self.rfid_tags = {\n",
    "            'A': np.array(self.rfid_tags_A),\n",
    "            'B': np.array(self.rfid_tags_B),\n",
    "            'C': np.array(self.rfid_tags_C),\n",
    "            'D': np.array(self.rfid_tags_D),\n",
    "            'E': np.array(self.rfid_tags_E)\n",
    "        }\n",
    "\n",
    "        # Initialize Kalman filter state\n",
    "        # State vector [x, y, theta, v_x, v_y, omega]\n",
    "        self.x = np.zeros((6, 1))\n",
    "        # State covariance matrix\n",
    "        self.P = np.eye(6) * 0.1\n",
    "        # Process noise\n",
    "        self.Q = np.eye(6) * 0.01\n",
    "        # Measurement noise for RFID tags\n",
    "        self.R_rfid = np.eye(2) * 0.1\n",
    "        # Measurement noise for odometry\n",
    "        self.R_odom = np.eye(3) * 0.05\n",
    "        # Last update time\n",
    "        self.last_time = self.get_clock().now().nanoseconds / 1e9\n",
    "        # Last pose for calculating velocity\n",
    "        self.last_pose = np.zeros(3)\n",
    "        # Flag to indicate if we've received initial pose\n",
    "        self.initialized = False\n",
    "\n",
    "        # setting up subscribers\n",
    "        self.odom_subscriber = self.create_subscription(\n",
    "            Odometry, \n",
    "            self.odom_topic, \n",
    "            self.odom_callback, \n",
    "            10\n",
    "        )\n",
    "        self.rfid_tag_subscriber = self.create_subscription(\n",
    "            PositionLabelledArray, \n",
    "            self.rfid_tag_poses_topic, \n",
    "            self.rfid_callback, \n",
    "            10\n",
    "        )\n",
    "        self.initial_pose_subscriber = self.create_subscription(\n",
    "            PoseWithCovarianceStamped, \n",
    "            self.initial_pose_topic, \n",
    "            self.initial_pose_callback, \n",
    "            10\n",
    "        )\n",
    "        self.real_base_link_subscriber = self.create_subscription(\n",
    "            PoseStamped, \n",
    "            self.real_base_link_pose_topic, \n",
    "            self.real_base_link_pose_callback, \n",
    "            10\n",
    "        )\n",
    "        \n",
    "        # Publisher for estimated pose\n",
    "        self.estimated_robot_pose_publisher = self.create_publisher(\n",
    "            PoseWithCovarianceStamped, \n",
    "            self.estimated_base_link_pose_topic, \n",
    "            10\n",
    "        )\n",
    "        \n",
    "        # setting up tf2 listener\n",
    "        self.tf_buffer = tf2_ros.Buffer()\n",
    "        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)\n",
    "        \n",
    "        self.get_logger().info(\"Kalman Filter initialized\")\n",
    "\n",
    "    def initial_pose_callback(self, msg):\n",
    "        \"\"\"\n",
    "        Callback for initial pose estimate from RVIZ\n",
    "        \"\"\"\n",
    "        # Extract position and orientation\n",
    "        position = msg.pose.pose.position\n",
    "        orientation = msg.pose.pose.orientation\n",
    "        \n",
    "        # Convert quaternion to Euler angles\n",
    "        _, _, yaw = euler_from_quaternion([orientation.x, orientation.y, orientation.z, orientation.w])\n",
    "        \n",
    "        # Reset state vector with initial pose\n",
    "        self.x[0, 0] = position.x\n",
    "        self.x[1, 0] = position.y\n",
    "        self.x[2, 0] = yaw\n",
    "        self.x[3:6, 0] = 0.0  # Reset velocities\n",
    "        \n",
    "        # Reset covariance matrix\n",
    "        self.P = np.eye(6) * 0.1\n",
    "        \n",
    "        # Reset last pose\n",
    "        self.last_pose = np.array([position.x, position.y, yaw])\n",
    "        \n",
    "        # Reset last time\n",
    "        self.last_time = self.get_clock().now().nanoseconds / 1e9\n",
    "        \n",
    "        # Set initialized flag\n",
    "        self.initialized = True\n",
    "        \n",
    "        self.get_logger().info(f\"Initial pose set: x={position.x:.2f}, y={position.y:.2f}, theta={yaw:.2f}\")\n",
    "        \n",
    "        # Publish initial estimated pose\n",
    "        self.publish_estimated_pose()\n",
    "\n",
    "    def real_base_link_pose_callback(self, msg):\n",
    "        \"\"\"\n",
    "        Updating the base_link pose based on the update in robile_rfid_tag_finder.py\n",
    "        \"\"\"\n",
    "        # This is just for visualization/debugging, not used in the filter\n",
    "        yaw = euler_from_quaternion([msg.pose.orientation.x, msg.pose.orientation.y, msg.pose.orientation.z, msg.pose.orientation.w])[2]\n",
    "        self.real_laser_link_pose = [msg.pose.position.x, msg.pose.position.y, yaw]\n",
    "        self.get_logger().debug(f\"Real base link pose: x={msg.pose.position.x:.2f}, y={msg.pose.position.y:.2f}, theta={yaw:.2f}\")\n",
    "\n",
    "    def predict(self, dt):\n",
    "        \"\"\"Prediction step of the Kalman filter\"\"\"\n",
    "        # State transition matrix\n",
    "        F = np.eye(6)\n",
    "        F[0, 3] = dt  # x += v_x * dt\n",
    "        F[1, 4] = dt  # y += v_y * dt\n",
    "        F[2, 5] = dt  # theta += omega * dt\n",
    "        \n",
    "        # Predict state\n",
    "        self.x = F @ self.x\n",
    "        # Predict covariance\n",
    "        self.P = F @ self.P @ F.T + self.Q\n",
    "        \n",
    "        # Log prediction step output\n",
    "        self.get_logger().info(f\"KF Predict: x={self.x[0,0]:.2f}, y={self.x[1,0]:.2f}, theta={self.x[2,0]:.2f}, P_diag={np.diag(self.P).tolist()}\")\n",
    "\n",
    "\n",
    "    def update_with_odom(self, odom_measurement):\n",
    "        \"\"\"Update step with odometry measurements\"\"\"\n",
    "        # Measurement matrix for odometry (x, y, theta)\n",
    "        H = np.zeros((3, 6))\n",
    "        H[0, 0] = 1  # x\n",
    "        H[1, 1] = 1  # y\n",
    "        H[2, 2] = 1  # theta\n",
    "        \n",
    "        # Ensure odom_measurement is a column vector (3,1)\n",
    "        # This explicitly reshapes it, which can prevent subtle broadcasting issues\n",
    "        # that might lead to unexpected dimensions in `y` later.\n",
    "        odom_measurement_col_vector = odom_measurement.reshape(-1, 1)\n",
    "\n",
    "        # Innovation (measurement residual)\n",
    "        # Use the explicitly reshaped column vector for `odom_measurement`\n",
    "        y = odom_measurement_col_vector - H @ self.x\n",
    "        \n",
    "        # Normalize theta difference to [-pi, pi]\n",
    "        y[2] = np.arctan2(np.sin(y[2]), np.cos(y[2]))\n",
    "        \n",
    "        # Reshape y to be a column vector (3,1) - this line becomes technically redundant but harmless\n",
    "        # if odom_measurement_col_vector was already (3,1)\n",
    "        y = y.reshape(-1, 1) \n",
    "        \n",
    "        # Innovation covariance\n",
    "        S = H @ self.P @ H.T + self.R_odom\n",
    "        \n",
    "        # Kalman gain\n",
    "        K = self.P @ H.T @ np.linalg.inv(S)\n",
    "        \n",
    "        # Update state\n",
    "        self.x = self.x + K @ y\n",
    "        \n",
    "        # Update covariance\n",
    "        self.P = (np.eye(6) - K @ H) @ self.P\n",
    "        \n",
    "        # Log odometry update output\n",
    "        self.get_logger().info(f\"KF Update Odom: x={self.x[0,0]:.2f}, y={self.x[1,0]:.2f}, theta={self.x[2,0]:.2f}, P_diag={np.diag(self.P).tolist()}\")\n",
    "\n",
    "\n",
    "    def update_with_rfid(self, rfid_measurements):\n",
    "        \"\"\"Update step with RFID measurements\"\"\"\n",
    "        if not rfid_measurements:\n",
    "            return\n",
    "            \n",
    "        for tag_id, measurement in rfid_measurements.items():\n",
    "            if tag_id not in self.rfid_tags:\n",
    "                continue\n",
    "                \n",
    "            # Get the true position of the RFID tag\n",
    "            tag_pos = self.rfid_tags[tag_id]\n",
    "            \n",
    "            # Measurement function (nonlinear)\n",
    "            # Expected measurement based on current state\n",
    "            dx = tag_pos[0] - self.x[0, 0]\n",
    "            dy = tag_pos[1] - self.x[1, 0]\n",
    "            expected_range = np.sqrt(dx**2 + dy**2)\n",
    "            expected_bearing = np.arctan2(dy, dx) - self.x[2, 0]\n",
    "            expected_measurement = np.array([expected_range, expected_bearing])\n",
    "            \n",
    "            # Actual measurement\n",
    "            actual_measurement = np.array(measurement)\n",
    "            \n",
    "            # Innovation (measurement residual)\n",
    "            y = actual_measurement - expected_measurement\n",
    "            \n",
    "            # Normalize bearing difference to [-pi, pi]\n",
    "            y[1] = np.arctan2(np.sin(y[1]), np.cos(y[1]))\n",
    "            \n",
    "            # Reshape y to be a column vector (2,1)\n",
    "            y = y.reshape(-1, 1)\n",
    "            \n",
    "            # Jacobian of measurement function\n",
    "            H = np.zeros((2, 6))\n",
    "            H[0, 0] = -dx / expected_range\n",
    "            H[0, 1] = -dy / expected_range\n",
    "            H[1, 0] = dy / (dx**2 + dy**2)\n",
    "            H[1, 1] = -dx / (dx**2 + dy**2)\n",
    "            H[1, 2] = -1\n",
    "            \n",
    "            # Innovation covariance\n",
    "            S = H @ self.P @ H.T + self.R_rfid\n",
    "            \n",
    "            # Kalman gain\n",
    "            K = self.P @ H.T @ np.linalg.inv(S)\n",
    "            \n",
    "            # Update state\n",
    "            self.x = self.x + K @ y\n",
    "            \n",
    "            # Update covariance\n",
    "            self.P = (np.eye(6) - K @ H) @ self.P\n",
    "            \n",
    "            # Log RFID update output\n",
    "            self.get_logger().info(f\"KF Update RFID ({tag_id}): x={self.x[0,0]:.2f}, y={self.x[1,0]:.2f}, theta={self.x[2,0]:.2f}, P_diag={np.diag(self.P).tolist()}\")\n",
    "\n",
    "\n",
    "    def odom_callback(self, msg):\n",
    "        \"\"\"\n",
    "        Callback for odometry messages\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            # Initialize with first odometry message\n",
    "            position = msg.pose.pose.position\n",
    "            orientation = msg.pose.pose.orientation\n",
    "            _, _, yaw = euler_from_quaternion([orientation.x, orientation.y, orientation.z, orientation.w])\n",
    "            \n",
    "            self.x[0, 0] = position.x\n",
    "            self.x[1, 0] = position.y\n",
    "            self.x[2, 0] = yaw\n",
    "            self.x[3:6, 0] = 0.0 # Initialize velocities to zero\n",
    "            self.last_pose = np.array([position.x, position.y, yaw])\n",
    "            self.last_time = self.get_clock().now().nanoseconds / 1e9\n",
    "            self.initialized = True\n",
    "            self.get_logger().info(f\"Initialized with odometry: x={position.x:.2f}, y={position.y:.2f}, theta={yaw:.2f}\")\n",
    "            self.publish_estimated_pose()\n",
    "            return\n",
    "        \n",
    "        # Extract position and orientation\n",
    "        position = msg.pose.pose.position\n",
    "        orientation = msg.pose.pose.orientation\n",
    "        \n",
    "        # Convert quaternion to Euler angles\n",
    "        _, _, yaw = euler_from_quaternion([orientation.x, orientation.y, orientation.z, orientation.w])\n",
    "        \n",
    "        # Create measurement vector [x, y, theta] as a column vector\n",
    "        # This explicitly makes it a (3,1) array\n",
    "        odom_measurement = np.array([[position.x], [position.y], [yaw]])\n",
    "        \n",
    "        # Get current time and calculate dt\n",
    "        current_time = self.get_clock().now().nanoseconds / 1e9\n",
    "        dt = current_time - self.last_time\n",
    "        \n",
    "        self.get_logger().info(f\"Odom Callback: dt={dt:.4f}\") # Added log for dt\n",
    "\n",
    "        if dt > 0:\n",
    "            # Calculate velocities\n",
    "            # Using current odometry position, not filtered state, for velocity calculation\n",
    "            dx = (position.x - self.last_pose[0]) / dt\n",
    "            dy = (position.y - self.last_pose[1]) / dt\n",
    "            # Normalize dtheta before dividing by dt\n",
    "            dtheta = np.arctan2(np.sin(yaw - self.last_pose[2]), np.cos(yaw - self.last_pose[2])) / dt\n",
    "            \n",
    "            # Update velocity estimates in state with a low-pass filter\n",
    "            # These values will then be used in the next prediction step\n",
    "            self.x[3, 0] = 0.7 * self.x[3, 0] + 0.3 * dx  \n",
    "            self.x[4, 0] = 0.7 * self.x[4, 0] + 0.3 * dy\n",
    "            self.x[5, 0] = 0.7 * self.x[5, 0] + 0.3 * dtheta\n",
    "            \n",
    "            # Predict step\n",
    "            self.predict(dt)\n",
    "            \n",
    "            # Update step with odometry\n",
    "            self.update_with_odom(odom_measurement)\n",
    "            \n",
    "            # Update last pose and time for next velocity calculation\n",
    "            self.last_pose = np.array([position.x, position.y, yaw])\n",
    "            self.last_time = current_time\n",
    "            \n",
    "            # Publish estimated pose\n",
    "            self.publish_estimated_pose()\n",
    "        else:\n",
    "            self.get_logger().warn(f\"dt is zero or negative ({dt:.4f}), skipping prediction and update.\")\n",
    "\n",
    "\n",
    "    def rfid_callback(self, msg):\n",
    "        \"\"\"\n",
    "        Based on the detected RFID tags, performing measurement update\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            self.get_logger().warn(\"RFID callback received but Kalman filter not initialized.\")\n",
    "            return\n",
    "            \n",
    "        # Process RFID tag detections\n",
    "        rfid_measurements = {}\n",
    "        \n",
    "        for tag in msg.positions:\n",
    "            # Extract tag ID using the correct attribute name\n",
    "            tag_id = tag.name\n",
    "                \n",
    "            # Extract position (relative to laser_link_frame as per your setup)\n",
    "            position = tag.position\n",
    "            \n",
    "            # Calculate range and bearing to the tag from the sensor's perspective\n",
    "            range_to_tag = np.sqrt(position.x**2 + position.y**2)\n",
    "            bearing_to_tag = np.arctan2(position.y, position.x)\n",
    "            \n",
    "            # Store measurement\n",
    "            rfid_measurements[tag_id] = [range_to_tag, bearing_to_tag]\n",
    "            \n",
    "            self.get_logger().debug(f\"Detected RFID tag {tag_id} at range={range_to_tag:.2f}, bearing={bearing_to_tag:.2f}\")\n",
    "        \n",
    "        # Update Kalman filter with RFID measurements\n",
    "        if rfid_measurements:\n",
    "            self.update_with_rfid(rfid_measurements)\n",
    "            self.publish_estimated_pose()\n",
    "        else:\n",
    "            self.get_logger().debug(\"No RFID measurements to process.\")\n",
    "\n",
    "\n",
    "    def publish_estimated_pose(self):\n",
    "        \"\"\"\n",
    "        Publish the current estimated pose\n",
    "        \"\"\"\n",
    "        # Create PoseWithCovarianceStamped message\n",
    "        pose_msg = PoseWithCovarianceStamped()\n",
    "        pose_msg.header.stamp = self.get_clock().now().to_msg()\n",
    "        pose_msg.header.frame_id = self.map_frame\n",
    "        \n",
    "        # Set position\n",
    "        pose_msg.pose.pose.position.x = self.x[0, 0]\n",
    "        pose_msg.pose.pose.position.y = self.x[1, 0]\n",
    "        pose_msg.pose.pose.position.z = 0.0\n",
    "        \n",
    "        # Set orientation (convert theta to quaternion)\n",
    "        q = quaternion_from_euler(0, 0, self.x[2, 0])\n",
    "        pose_msg.pose.pose.orientation.x = q[0]\n",
    "        pose_msg.pose.pose.orientation.y = q[1]\n",
    "        pose_msg.pose.pose.orientation.z = q[2]\n",
    "        pose_msg.pose.pose.orientation.w = q[3]\n",
    "        \n",
    "        # Set covariance (6x6 matrix in row-major order)\n",
    "        # Only set position and orientation covariance relevant for PoseWithCovarianceStamped\n",
    "        # Note: The covariance matrix self.P is 6x6, covering [x, y, theta, vx, vy, omega]\n",
    "        # The PoseWithCovarianceStamped message expects a 6x6 covariance for [x, y, z, roll, pitch, yaw]\n",
    "        # We map x, y, yaw from our 6x6 P to the corresponding spots.\n",
    "        covariance = np.zeros(36)\n",
    "        covariance[0] = self.P[0, 0]   # Variance of x\n",
    "        covariance[1] = self.P[0, 1]   # Covariance of x and y\n",
    "        covariance[5] = self.P[0, 2]   # Covariance of x and theta\n",
    "        \n",
    "        covariance[6] = self.P[1, 0]   # Covariance of y and x\n",
    "        covariance[7] = self.P[1, 1]   # Variance of y\n",
    "        covariance[11] = self.P[1, 2]  # Covariance of y and theta\n",
    "        \n",
    "        covariance[30] = self.P[2, 0]  # Covariance of theta and x\n",
    "        covariance[31] = self.P[2, 1]  # Covariance of theta and y\n",
    "        covariance[35] = self.P[2, 2]  # Variance of theta\n",
    "        \n",
    "        pose_msg.pose.covariance = covariance.tolist()\n",
    "        \n",
    "        # Publish the pose\n",
    "        self.estimated_robot_pose_publisher.publish(pose_msg)\n",
    "        \n",
    "        self.get_logger().info(f\"Published estimated pose: x={self.x[0,0]:.2f}, y={self.x[1,0]:.2f}, theta={self.x[2,0]:.2f}\")\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "\n",
    "    try:\n",
    "        localisation_using_kalman_filter = LocalisationUsingKalmanFilter()\n",
    "        rclpy.spin(localisation_using_kalman_filter)\n",
    "\n",
    "    finally:\n",
    "        localisation_using_kalman_filter.destroy_node()\n",
    "        rclpy.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f985e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "604f8d1c039395c4535afec3fd6a1db5",
     "grade": false,
     "grade_id": "cell-41799b9311561a40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, comment on your observations while evaluating your implementation in the cell below, and include relevant screenshots to verify your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7286110",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd39c3ea6aa51c21896d72bfd78b47bf",
     "grade": true,
     "grade_id": "cell-fd82eec8922f9e03",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "1. We were able to implement the kalman filter and also visualize it on Rviz.\n",
    "2. The kalman filter is basically taking the input and denoising the signal and producing a smooth transition between the different poses.\n",
    "3. The kalman filter is always following the pose direction but its transitions are smoother.\n",
    "\n",
    "Video of implementation:\n",
    "\n",
    "https://drive.google.com/file/d/1iPsIhFSOqTgQiYx8wNW_6IhWnH5Wqb0m/view?usp=drive_link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
